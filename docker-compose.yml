version: '3.8'

services:
  agent:
    build: .
    container_name: agent-api
    ports:
      - "8080:8080"
    environment:
      - TOOL_MANAGER_URL=http://tool-manager:8000
      - OLLAMA_BASE_URL=http://ollama:11434
      - DEFAULT_MODEL=gemma3
      - ENVIRONMENT=production
    depends_on:
      - ollama-service
    networks:
      - agent-network
    restart: unless-stopped

  tool-manager:
    image: tool-manager-api:latest  # You need to build this image separately
    container_name: tool-manager-api
    ports:
      - "8000:8000"
    networks:
      - agent-network
    volumes:
      - tool-manager-data:/app/data
    restart: unless-stopped

  # Base Ollama configuration (CPU mode - macOS fallback)
  ollama-service:
    image: ollama/ollama:latest
    container_name: ollama-service
    profiles: [cpu]
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - agent-network
    restart: unless-stopped

  # NVIDIA-specific configuration
  ollama-nvidia:
    image: ollama/ollama:latest
    container_name: ollama-service
    profiles: [nvidia]
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - agent-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # AMD-specific configuration
  ollama-amd:
    image: ollama/ollama:latest
    container_name: ollama-service
    profiles: [amd]
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - agent-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: amd
              count: 1
              capabilities: [gpu]

networks:
  agent-network:
    driver: bridge

volumes:
  tool-manager-data:
  ollama-data: 